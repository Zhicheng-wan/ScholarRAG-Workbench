{
  "query_1": {
    "relevant_docs": [
      "arxiv:2307.10169#methods:part-3",
      "arxiv:2303.18223#result:part-11",
      "arxiv:2307.10169#methods:part-2",
      "arxiv:2307.10169#methods:part-5",
      "arxiv:2307.10169#methods:part-4",
      "arxiv:2412.10543#introduction:part-1",
      "arxiv:2303.18223#model:part-35"
    ],
    "relevance_scores": {
      "arxiv:2307.10169#methods:part-3": 1.0,
      "arxiv:2303.18223#result:part-11": 0.5,
      "arxiv:2307.10169#methods:part-2": 0.5,
      "arxiv:2307.10169#methods:part-5": 1.0,
      "arxiv:2307.10169#methods:part-4": 1.0,
      "arxiv:2412.10543#introduction:part-1": 0.5,
      "arxiv:2303.18223#model:part-35": 0.5
    },
    "notes": "Several papers focus on reducing hallucinations in retrieval-augmented generation (RAG) systems. One of the main studies (2307.10169) shows that grounding model inputs on external knowledge can reduce hallucinations by up to 85%. The same work also introduces decoding-level techniques like diverse beam search and Confident Decoding, both targeting hallucination reduction during generation. Another paper discusses REALM, which integrates retrieved documents during pretraining to provide factual grounding. While these methods show strong improvements, other papers note that retrieval alone isn\u2019t enough to fully eliminate hallucinations. Overall, the highest-scoring sources (1.0) directly propose concrete techniques, while the partially relevant ones (0.5) only discuss the issue or provide broader context."
  },
  "query_2": {
    "relevant_docs": [
      "arxiv:2306.09782#introduction:part-1",
      "arxiv:2304.01933#method:part-6",
      "arxiv:2106.09685#introduction:part-10"
    ],
    "relevance_scores": {
      "arxiv:2306.09782#introduction:part-1": 0.5,
      "arxiv:2304.01933#method:part-6": 1.0,
      "arxiv:2106.09685#introduction:part-10": 1.0
    },
    "notes": "These papers explore parameter-efficient fine-tuning methods such as LoRA and Prefix-Tuning. The introduction in 2306.09782 mentions both as practical options for resource-limited settings, though they sometimes trail full fine-tuning slightly. Other studies (2304.01933, 2106.09685) provide head-to-head comparisons and show that LoRA, when configured correctly, can match or even outperform full fine-tuning on benchmarks like WikiSQL and MultiNLI. The highly relevant papers (score 1.0) contain direct empirical evaluations, while the moderately relevant one (0.5) provides background context."
  },
  "query_3": {
    "relevant_docs": [
      "arxiv:2001.08361#model:part-2",
      "arxiv:333078981_693988129081760_4712707815225756708_n#introduction:part-1",
      "arxiv:2303.18223#introduction:part-7",
      "arxiv:2302.13971#introduction:part-1",
      "arxiv:2203.15556#model:part-3",
      "arxiv:2307.09288#related-work:part-1",
      "arxiv:2204.02311#related-work:part-2",
      "arxiv:2203.15556#model:part-2"
    ],
    "relevance_scores": {
      "arxiv:2001.08361#model:part-2": 1.0,
      "arxiv:333078981_693988129081760_4712707815225756708_n#introduction:part-1": 1.0,
      "arxiv:2303.18223#introduction:part-7": 0.5,
      "arxiv:2302.13971#introduction:part-1": 0.5,
      "arxiv:2203.15556#model:part-3": 0.5,
      "arxiv:2307.09288#related-work:part-1": 0.5,
      "arxiv:2204.02311#related-work:part-2": 0.5,
      "arxiv:2203.15556#model:part-2": 1.0
    },
    "notes": "These works examine scaling laws and compute-efficiency trade-offs for large language models. The classic Kaplan et al. (2020) paper defined the original scaling laws, showing predictable performance gains with model and data size. The Chinchilla analysis (Hoffmann et al. 2022) refined that insight, showing that smaller models trained on more data can be compute-optimal. The LLaMA report (2302.13971) reinforces this, suggesting that smaller, well-trained models can outperform massive ones at equal inference cost. Supporting papers discuss related topics like multilingual scaling and retrieval-based efficiency. Overall, the top-ranked papers (1.0) form the foundation for modern scaling discussions, while 0.5 papers provide helpful but secondary context."
  },
  "query_4": {
    "relevant_docs": [
      "arxiv:2303.18223#result:part-14",
      "arxiv:2305.14314#evaluation:part-1",
      "arxiv:palm2techreport#evaluation:part-7"
    ],
    "relevance_scores": {
      "arxiv:2303.18223#result:part-14": 1.0,
      "arxiv:2305.14314#evaluation:part-1": 1.0,
      "arxiv:palm2techreport#evaluation:part-7": 0.5
    },
    "notes": "The top sources clearly identify reasoning and math benchmarks. Standard datasets include GSM8K, SVAMP, and MATH for mathematical reasoning, and MMLU for general knowledge reasoning. PaLM 2 is also evaluated on GSM8K, MATH, and MGSM, confirming these as common benchmarks. The 1.0 papers directly enumerate these datasets, while the 0.5 reference mentions them in context. Together, they outline the core evaluation suite for reasoning and math ability."
  },
  "query_5": {
    "relevant_docs": [
      "arxiv:2305.18290#related-work:part-2",
      "arxiv:2303.18223#model:part-5",
      "arxiv:2203.02155#related-work:part-1"
    ],
    "relevance_scores": {
      "arxiv:2305.18290#related-work:part-2": 1.0,
      "arxiv:2303.18223#model:part-5": 0.5,
      "arxiv:2203.02155#related-work:part-1": 1.0
    },
    "notes": "These papers compare how RLHF is used across models like InstructGPT, Sparrow, and Claude. InstructGPT follows the classic 3-step RLHF process: supervised fine-tuning, reward model training, and PPO optimization. Sparrow modifies this with human rule-based safety constraints, while Anthropic\u2019s Claude introduces Constitutional AI, replacing some human feedback with AI-guided principles. The 1.0 sources provide detailed contrasts, while the 0.5 source mentions the topic only briefly."
  },
  "query_6": {
    "relevant_docs": [
      "arxiv:2211.05100#abstract:part-2",
      "arxiv:2211.05100#model:part-5",
      "arxiv:2307.03172#abstract",
      "arxiv:2211.09110#model:part-6"
    ],
    "relevance_scores": {
      "arxiv:2211.05100#abstract:part-2": 1.0,
      "arxiv:2211.05100#model:part-5": 1.0,
      "arxiv:2307.03172#abstract": 0.5,
      "arxiv:2211.09110#model:part-6": 0.5
    },
    "notes": "These works cover multilingual large language models. BLOOM, a 176B model trained on 46 natural and 13 programming languages, is the flagship example. It emphasizes evaluation in the source language instead of translation. Similarly, mGPT trains on data from about 60 languages, proving that multilingualism is achievable even at moderate scales. Other works, like PaLM, started English-dominant but improved cross-lingual capabilities with additional data. In summary, BLOOM and mGPT represent massive multilingual pretraining, while models like PaLM 2 use targeted fine-tuning to enhance multilingual performance."
  },
  "query_7": {
    "relevant_docs": [
      "arxiv:2307.03172#abstract",
      "arxiv:2307.03172#model:part-3",
      "arxiv:2307.03172#introduction:part-3",
      "arxiv:2412.10543#introduction:part-1"
    ],
    "relevance_scores": {
      "arxiv:2307.03172#abstract": 0.5,
      "arxiv:2307.03172#model:part-3": 0.5,
      "arxiv:2307.03172#introduction:part-3": 0.5,
      "arxiv:2412.10543#introduction:part-1": 0.5
    },
    "notes": "Few papers propose new methods for extending long-context capabilities, but some provide insightful analysis. One study (2307.03172) shows that standard transformers often fail to use information from the middle of long inputs, producing a U-shaped performance curve. While it doesn\u2019t offer a fix, it highlights the need for more robust long-context handling. Another paper suggests retrieval-augmentation as an alternative, fetching relevant chunks on demand instead of feeding the entire long sequence. Overall, these papers emphasize the challenge of maintaining context awareness across long inputs and the growing interest in hybrid retrieval approaches."
  },
  "query_8": {
    "relevant_docs": [
      "arxiv:2310.20707#model:part-12",
      "arxiv:2310.20707#model:part-7",
      "arxiv:2303.18223#model:part-13",
      "arxiv:2310.20707#introduction:part-2",
      "arxiv:20-074#abstract:part-31",
      "arxiv:2005.14165#results:part-27"
    ],
    "relevance_scores": {
      "arxiv:2310.20707#model:part-12": 1.0,
      "arxiv:2310.20707#model:part-7": 1.0,
      "arxiv:2303.18223#model:part-13": 1.0,
      "arxiv:2310.20707#introduction:part-2": 1.0,
      "arxiv:20-074#abstract:part-31": 0.5,
      "arxiv:2005.14165#results:part-27": 1.0
    },
    "notes": "These papers focus on data contamination and memorization issues in LLM training. The comprehensive 2310.20707 study discusses duplication, overlap, and documentation practices for improving data quality. Another paper outlines preprocessing steps like filtering and deduplication at multiple levels. The GPT-3 paper (2005.14165) also stresses test data decontamination to prevent inflated results. Collectively, these high-relevance works propose concrete solutions for reducing memorization, while the older or tangential ones provide supporting context."
  },
  "query_9": {
    "relevant_docs": [
      "arxiv:2203.02155#model:part-12",
      "arxiv:2304.01373#abstract:part-2",
      "arxiv:2211.05100#evaluation:part-5"
    ],
    "relevance_scores": {
      "arxiv:2203.02155#model:part-12": 1.0,
      "arxiv:2304.01373#abstract:part-2": 1.0,
      "arxiv:2211.05100#evaluation:part-5": 0.5
    },
    "notes": "These studies highlight the importance of open-source LLMs for transparency and reproducibility. One argues that depending solely on closed APIs centralizes control and limits verification, while open releases like LLaMA and Falcon enable independent analysis. The Pythia suite (2304.01373) extends this by releasing full training data and checkpoints to allow scaling experiments. BLOOM also showcases the impact of community-driven collaboration. The strongest papers (score 1.0) directly address openness and reproducibility, while the 0.5 paper highlights related community engagement."
  },
  "query_10": {
    "relevant_docs": [
      "arxiv:2307.10169#methods:part-7",
      "arxiv:2305.18290#abstract"
    ],
    "relevance_scores": {
      "arxiv:2307.10169#methods:part-7": 1.0,
      "arxiv:2305.18290#abstract": 1.0
    },
    "notes": "The selected papers introduce new alignment methods that go beyond standard RLHF. A recent survey (2307.10169) discusses whether the reinforcement learning step is even necessary, introducing Direct Preference Optimization (DPO) as a simpler supervised alternative. DPO replaces the reward model and PPO loop with direct optimization over human preference data. The original DPO paper (2305.18290) confirms that it matches or outperforms RLHF on tasks like summarization and sentiment control, with greater stability. These works also mention related trends, such as purely supervised alignment and Constitutional AI, showing that much of alignment may be achieved without complex RL steps."
  },
  "query_11": {
    "relevant_docs": [
      "blog:www.therobotreport.com#robotics-310",
      "blog:www.therobotreport.com#robotics-311",
      "arxiv:2510.13794#abstract",
      "arxiv:2510.13704#abstract",
      "arxiv:2510.13625#abstract",
      "blog:www.technologyreview.com#robotics-316",
      "arxiv:2510.13358#abstract"
    ],
    "relevance_scores": {
      "blog:www.therobotreport.com#robotics-310": 1.0,
      "blog:www.therobotreport.com#robotics-311": 1.0,
      "arxiv:2510.13794#abstract": 1.0,
      "arxiv:2510.13704#abstract": 1.0,
      "arxiv:2510.13625#abstract": 0.5,
      "blog:www.technologyreview.com#robotics-316": 0.5,
      "arxiv:2510.13358#abstract": 0.5
    },
    "notes": "The most recent advancements in humanoid robot design and control are covered extensively in 2024 blog articles and October 2024 papers. The Robot Report's top stories highlight that humanoid robots dominated 2024, appearing in six of the top 10 robotics stories. Recent papers focus on RL-based motion imitation for agile humanoid behaviors (2510.13794), actor-critic methods for continuous control with humanoid locomotion benchmarks (2510.13704), and computer vision modules optimized for humanoid robots (2510.13625). The highly relevant sources (1.0) directly discuss humanoid design and control advances from 2024, while partially relevant ones (0.5) provide supporting context on legged robotics and robust control methods."
  },
  "query_12": {
    "relevant_docs": [
      "arxiv:2307.10169#abstract",
      "arxiv:2303.18223#abstract",
      "arxiv:2510.13778#abstract",
      "arxiv:2510.13149#abstract",
      "arxiv:2302.14045#abstract",
      "arxiv:2005.14165#abstract",
      "arxiv:2212.03551#abstract"
    ],
    "relevance_scores": {
      "arxiv:2307.10169#abstract": 1.0,
      "arxiv:2303.18223#abstract": 1.0,
      "arxiv:2510.13778#abstract": 1.0,
      "arxiv:2510.13149#abstract": 1.0,
      "arxiv:2302.14045#abstract": 1.0,
      "arxiv:2005.14165#abstract": 0.5,
      "arxiv:2212.03551#abstract": 0.5
    },
    "notes": "Multiple papers discuss integrating LLMs and generative AI into robotics. Two comprehensive surveys (2307.10169, 2303.18223) cover LLM applications in robotics including task planning, embodied AI, navigation, and instruction following. Recent work introduces Vision-Language-Action (VLA) models for robotic manipulation with spatial reasoning (2510.13778) and long-horizon manipulation tasks (2510.13149). KOSMOS-1 (2302.14045) presents a Multimodal LLM for perception, action, and world modeling in robotics. The highly relevant papers (1.0) directly propose or survey LLM integration in robot systems, while partially relevant ones (0.5) discuss foundation models with potential robotics applications."
  },
  "query_13": {
    "relevant_docs": [
      "arxiv:2510.13778#model:part-10",
      "arxiv:2510.13778#model:part-13",
      "arxiv:2510.13149#abstract",
      "arxiv:2303.18223#evaluation",
      "arxiv:2312.07104#introduction",
      "arxiv:2005.14165#abstract"
    ],
    "relevance_scores": {
      "arxiv:2510.13778#model:part-10": 1.0,
      "arxiv:2510.13778#model:part-13": 1.0,
      "arxiv:2510.13149#abstract": 1.0,
      "arxiv:2303.18223#evaluation": 0.5,
      "arxiv:2312.07104#introduction": 0.5,
      "arxiv:2005.14165#abstract": 0.5
    },
    "notes": "Research on robot manipulation in unstructured environments focuses on VLA models for cluttered scenes. Key work (2510.13778) demonstrates spatial grounding and pick-and-place tasks in real-world cluttered scenarios with Franka robotic arms, including instruction-following capabilities for complex manipulation. Another study (2510.13149) addresses manipulation under diverse perturbations and composing learned skills for novel long-horizon tasks in unstructured settings. The highly relevant papers (1.0) directly evaluate manipulation and grasping in cluttered or unstructured real-world environments, while partially relevant ones (0.5) discuss embodied AI benchmarks and task specification methods applicable to manipulation."
  },
  "query_14": {
    "relevant_docs": [
      "arxiv:2510.13778#model:part-2",
      "arxiv:2510.13625#abstract",
      "arxiv:2510.13626#abstract",
      "arxiv:2302.14045#abstract",
      "arxiv:2510.13778#model:part-4",
      "arxiv:2510.13594#abstract",
      "arxiv:2510.13149#abstract"
    ],
    "relevance_scores": {
      "arxiv:2510.13778#model:part-2": 1.0,
      "arxiv:2510.13625#abstract": 1.0,
      "arxiv:2510.13626#abstract": 1.0,
      "arxiv:2302.14045#abstract": 1.0,
      "arxiv:2510.13778#model:part-4": 1.0,
      "arxiv:2510.13594#abstract": 0.5,
      "arxiv:2510.13149#abstract": 0.5
    },
    "notes": "Robot perception improvements using vision-based and multimodal approaches are extensively covered in recent work. Key papers present multimodal VLMs for robot perception combining vision, language, and spatial understanding (2510.13778), YOLOv9-based vision modules addressing computational constraints (2510.13625), and systematic analysis of visual robustness under perturbations like lighting changes and sensor noise (2510.13626). KOSMOS-1 (2302.14045) demonstrates multimodal perception capabilities across general modalities. The highly relevant sources (1.0) directly propose or evaluate vision-based and multimodal perception methods for robotics, while partially relevant ones (0.5) mention vision integration as supporting components."
  },
  "query_15": {
    "relevant_docs": [
      "blog:www.therobotreport.com#robotics-311",
      "blog:www.therobotreport.com#robotics-308",
      "blog:blog.robotiq.com#robotics-323",
      "blog:robohub.org#robotics-322",
      "blog:medium.com#body:part-12"
    ],
    "relevance_scores": {
      "blog:www.therobotreport.com#robotics-311": 1.0,
      "blog:www.therobotreport.com#robotics-308": 1.0,
      "blog:blog.robotiq.com#robotics-323": 1.0,
      "blog:robohub.org#robotics-322": 0.5,
      "blog:medium.com#body:part-12": 0.5
    },
    "notes": "Human-robot collaboration in industrial settings is extensively discussed in robotics blogs from 2024. The Robot Report's coverage highlights industry collaborations, partnerships, and collaborative robot (cobot) deployments in industrial applications. Robotiq's blog focuses on collaborative robotics and automation solutions for manufacturing. The highly relevant sources (1.0) directly address human-robot collaboration challenges and solutions in industrial contexts, including safety, programming simplicity, and workforce integration. Partially relevant sources (0.5) discuss broader human-robot interaction topics and AI agents for collaborative systems."
  },
  "query_16": {
    "relevant_docs": [
      "blog:www.therobotreport.com#robotics-310",
      "blog:www.therobotreport.com#robotics-311",
      "blog:www.therobotreport.com#robotics-308",
      "blog:www.aethon.com#robotics-324",
      "blog:www.technologyreview.com#robotics-315",
      "blog:medium.com#body:part-9",
      "arxiv:2510.13686#introduction"
    ],
    "relevance_scores": {
      "blog:www.therobotreport.com#robotics-310": 1.0,
      "blog:www.therobotreport.com#robotics-311": 1.0,
      "blog:www.therobotreport.com#robotics-308": 1.0,
      "blog:www.aethon.com#robotics-324": 1.0,
      "blog:www.technologyreview.com#robotics-315": 1.0,
      "blog:medium.com#body:part-9": 0.5,
      "arxiv:2510.13686#introduction": 0.5
    },
    "notes": "Multiple blog articles cover 2024 breakthroughs in autonomous mobile robots (AMRs) and warehouse automation. The Robot Report's year-end and monthly top stories (robotics-310, -311, -308) highlight AMR deployments, warehouse automation milestones, and novel autonomous navigation solutions. Aethon's blog discusses AMR partnerships and developments. MIT Technology Review examines mobile robots and warehouse applications with future implications. The highly relevant sources (1.0) are blog articles specifically reporting on 2024 AMR and warehouse automation breakthroughs, while partially relevant ones (0.5) discuss related autonomous systems and AI agents in warehouse contexts."
  },
  "query_17": {
    "relevant_docs": [
      "arxiv:2510.13794#abstract",
      "arxiv:2510.13358#abstract",
      "arxiv:2510.13704#abstract",
      "arxiv:2510.13367#abstract",
      "arxiv:2510.13626#abstract",
      "blog:medium.com#body:part-2",
      "arxiv:2412.19437#introduction"
    ],
    "relevance_scores": {
      "arxiv:2510.13794#abstract": 1.0,
      "arxiv:2510.13358#abstract": 1.0,
      "arxiv:2510.13704#abstract": 1.0,
      "arxiv:2510.13367#abstract": 1.0,
      "arxiv:2510.13626#abstract": 0.5,
      "blog:medium.com#body:part-2": 0.5,
      "arxiv:2412.19437#introduction": 0.5
    },
    "notes": "Multiple papers focus on RL and imitation learning for robotic motion control. Core work includes RL-based motion imitation for agile, life-like robot behaviors (2510.13794), offline RL for robust control under action-space perturbations (2510.13358), actor-critic methods for continuous control with environment parallelization (2510.13704), and transformers in online model-free RL (2510.13367). The highly relevant papers (1.0) directly propose or evaluate RL/imitation learning methods specifically for robotic motion control tasks, while partially relevant ones (0.5) discuss RL applications in robotics more broadly or VLA models incorporating RL training."
  },
  "query_18": {
    "relevant_docs": [
      "blog:www.sciencedaily.com#robotics-313",
      "arxiv:2307.09288#model:part-23",
      "arxiv:10000000_662098952474184_2584067087619170692_n#model:part-23",
      "blog:blog.robotiq.com#robotics-323",
      "blog:medium.com#body:part-13"
    ],
    "relevance_scores": {
      "blog:www.sciencedaily.com#robotics-313": 1.0,
      "arxiv:2307.09288#model:part-23": 0.5,
      "arxiv:10000000_662098952474184_2584067087619170692_n#model:part-23": 0.5,
      "blog:blog.robotiq.com#robotics-323": 0.5,
      "blog:medium.com#body:part-13": 0.5
    },
    "notes": "Robotic safety and explainable AI are discussed primarily in robotics news and blog coverage. ScienceDaily's robotics news covers safety, trustworthy AI, and explainable approaches in robotics systems. The Llama 2 papers discuss safety preprompts and responsible AI considerations applicable to robot decision-making systems. Robotiq's blog addresses robot safety standards for industrial applications, while Medium discusses explainable AI (XAI) and responsible AI for autonomous systems. The highly relevant source (1.0) directly focuses on robotics safety and explainability, while partially relevant ones (0.5) discuss safety and explainability in AI systems with potential robotics applications."
  },
  "query_19": {
    "relevant_docs": [
      "arxiv:2510.13625#introduction",
      "arxiv:2510.13625#conclusions",
      "arxiv:2510.13594#abstract",
      "blog:www.sciencedaily.com#robotics-313"
    ],
    "relevance_scores": {
      "arxiv:2510.13625#introduction": 1.0,
      "arxiv:2510.13625#conclusions": 1.0,
      "arxiv:2510.13594#abstract": 0.5,
      "blog:www.sciencedaily.com#robotics-313": 0.5
    },
    "notes": "Energy efficiency and hardware optimization in robotics are addressed in recent work focusing on computationally constrained environments. A key paper (2510.13625) discusses hardware optimization for robotics with battery considerations and efficient vision processing using YOLOv9, summarizing computational challenges and targeted optimizations. ScienceDaily's robotics news mentions energy-efficient approaches including bacterial-powered neurons and battery technology. The highly relevant papers (1.0) directly propose or analyze hardware and energy optimization methods for robotic systems, while partially relevant ones (0.5) mention computational efficiency and resource considerations as supporting aspects."
  },
  "query_20": {
    "relevant_docs": [
      "blog:medium.com#body:part-13",
      "blog:medium.com#body:part-16",
      "blog:www.sciencedaily.com#robotics-313",
      "arxiv:2211.09110#model:part-4",
      "arxiv:2303.18223#evaluation"
    ],
    "relevance_scores": {
      "blog:medium.com#body:part-13": 1.0,
      "blog:medium.com#body:part-16": 1.0,
      "blog:www.sciencedaily.com#robotics-313": 1.0,
      "arxiv:2211.09110#model:part-4": 0.5,
      "arxiv:2303.18223#evaluation": 0.5
    },
    "notes": "Societal and ethical impacts of deploying robots are discussed in multiple blog posts and survey papers. Medium articles cover ethical and responsible AI, bias mitigation, fairness in autonomous vehicles, and robotics deployments, as well as applications of AI agents in robotics with ethical considerations. ScienceDaily's robotics news discusses societal implications and ethical considerations in robotics research and deployment. The highly relevant sources (1.0) directly address societal and ethical impacts of real-world robot deployment, while partially relevant ones (0.5) discuss responsible deployment considerations for language models in robotic systems and broader societal impact assessments."
  },
  "query_21": {
    "relevant_docs": [
      "arxiv:2020.aacl-main.88#abstract",
      "arxiv:2211.10438#related-work",
      "arxiv:2304.01373#abstract:part-4",
      "arxiv:2301.00774#introduction:part-1",
      "arxiv:NIPS-1989-optimal-brain-damage-Paper#introduction",
      "arxiv:2211.10438#abstract:part-2"
    ],
    "relevance_scores": {
      "arxiv:2020.aacl-main.88#abstract": 1.0,
      "arxiv:2211.10438#related-work": 0.5,
      "arxiv:2304.01373#abstract:part-4": 0.5,
      "arxiv:2301.00774#introduction:part-1": 1.0,
      "arxiv:NIPS-1989-optimal-brain-damage-Paper#introduction": 1.0,
      "arxiv:2211.10438#abstract:part-2": 0.5
    },
    "notes": "Query asks about architectures for efficient inference of LLMs. The most relevant papers discuss distillation, quantization, and sparse models for reducing inference costs. The 2020.aacl paper discusses efficient multi-task models. The 2301.00774 and NIPS-1989 papers cover neural network pruning and efficiency. Papers with score 1.0 directly address inference efficiency architectures, while 0.5 papers discuss LLM architectures more generally or mention efficiency in passing."
  },
  "query_22": {
    "relevant_docs": [
      "arxiv:2212.03551#introduction:part-15",
      "arxiv:2307.10169#methods:part-1",
      "arxiv:2303.18223#approach:part-19",
      "arxiv:2212.03551#approach:part-1",
      "arxiv:2212.03551#introduction:part-1"
    ],
    "relevance_scores": {
      "arxiv:2212.03551#introduction:part-15": 1.0,
      "arxiv:2307.10169#methods:part-1": 1.0,
      "arxiv:2303.18223#approach:part-19": 1.0,
      "arxiv:2212.03551#approach:part-1": 1.0,
      "arxiv:2212.03551#introduction:part-1": 0.5
    },
    "notes": "Query asks about chain-of-thought prompting. The 2212.03551 paper appears to be directly about CoT prompting (multiple sections highly relevant). The 2307.10169 paper discusses prompt chaining methods. The 2303.18223 paper discusses graph-based reasoning (ToT - Tree of Thoughts). All top papers (1.0) directly propose or analyze step-by-step reasoning methods."
  },
  "query_23": {
    "relevant_docs": [
      "arxiv:20-074#abstract:part-10",
      "arxiv:language_models_are_unsupervised_multitask_learners#abstract:part-3",
      "arxiv:2005.14165#approach:part-2",
      "arxiv:20-074#introduction:part-1",
      "arxiv:2005.14165#abstract:part-1"
    ],
    "relevance_scores": {
      "arxiv:20-074#abstract:part-10": 1.0,
      "arxiv:language_models_are_unsupervised_multitask_learners#abstract:part-3": 1.0,
      "arxiv:2005.14165#approach:part-2": 1.0,
      "arxiv:20-074#introduction:part-1": 0.5,
      "arxiv:2005.14165#abstract:part-1": 0.5
    },
    "notes": "Query asks about few-shot and zero-shot learning methods. The GPT-2 paper (language_models_are_unsupervised_multitask_learners) demonstrates zero-shot transfer. The GPT-3 paper (2005.14165) is the canonical few-shot learning work. The 20-074 paper discusses Natural Language Decathlon and multi-task zero-shot evaluation. Papers with 1.0 directly demonstrate or analyze few/zero-shot capabilities."
  },
  "query_24": {
    "relevant_docs": [
      "arxiv:Adaptive-mixtures-of-local-experts#abstract:part-8",
      "arxiv:1701.06538#abstract:part-6",
      "arxiv:1701.06538#abstract:part-4",
      "arxiv:1701.06538#model:part-1",
      "arxiv:Adaptive-mixtures-of-local-experts#introduction"
    ],
    "relevance_scores": {
      "arxiv:Adaptive-mixtures-of-local-experts#abstract:part-8": 1.0,
      "arxiv:1701.06538#abstract:part-6": 1.0,
      "arxiv:1701.06538#abstract:part-4": 1.0,
      "arxiv:1701.06538#model:part-1": 1.0,
      "arxiv:Adaptive-mixtures-of-local-experts#introduction": 0.5
    },
    "notes": "Query asks about mixture-of-experts architectures for scaling. The Adaptive-mixtures paper is the foundational MoE work. The 1701.06538 paper (Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer) is a key modern MoE paper for scaling. All 1.0 papers directly describe MoE architectures and their scaling properties."
  },
  "query_25": {
    "relevant_docs": [
      "arxiv:2305.11627#methods:part-1",
      "arxiv:2305.19268#introduction:part-1",
      "arxiv:2306.11695#introduction:part-1",
      "arxiv:2305.11627#abstract",
      "arxiv:NIPS-1989-optimal-brain-damage-Paper#model",
      "arxiv:NIPS-1992-second-order-derivatives-for-network-pruning-optimal-brain-surgeon-Paper#introduction"
    ],
    "relevance_scores": {
      "arxiv:2305.11627#methods:part-1": 1.0,
      "arxiv:2305.19268#introduction:part-1": 1.0,
      "arxiv:2306.11695#introduction:part-1": 1.0,
      "arxiv:2305.11627#abstract": 1.0,
      "arxiv:NIPS-1989-optimal-brain-damage-Paper#model": 0.5,
      "arxiv:NIPS-1992-second-order-derivatives-for-network-pruning-optimal-brain-surgeon-Paper#introduction": 0.5
    },
    "notes": "Query asks about model compression and quantization. The 2305.11627 paper is LLM-Pruner. The 2305.19268 and 2306.11695 papers discuss compression for large language models. The NIPS papers are foundational pruning works. Papers with 1.0 directly address LLM compression/quantization, while 0.5 papers cover general neural network compression."
  },
  "query_26": {
    "relevant_docs": [
      "arxiv:2005.14165#abstract:part-1",
      "arxiv:2005.14165#approach:part-2",
      "arxiv:20-074#abstract:part-10",
      "arxiv:2301.00774#model:part-3",
      "arxiv:language_models_are_unsupervised_multitask_learners#abstract:part-3"
    ],
    "relevance_scores": {
      "arxiv:2005.14165#abstract:part-1": 1.0,
      "arxiv:2005.14165#approach:part-2": 1.0,
      "arxiv:20-074#abstract:part-10": 0.5,
      "arxiv:2301.00774#model:part-3": 0.5,
      "arxiv:language_models_are_unsupervised_multitask_learners#abstract:part-3": 1.0
    },
    "notes": "Query asks about techniques enabling in-context learning. GPT-3 (2005.14165) demonstrates and analyzes in-context learning extensively. GPT-2 (language_models_are_unsupervised_multitask_learners) shows early in-context capabilities. Papers with 1.0 directly demonstrate or analyze in-context learning mechanisms."
  },
  "query_27": {
    "relevant_docs": [
      "arxiv:2310.05492#abstract",
      "arxiv:2211.05100#model:part-1",
      "arxiv:2303.18223#result:part-15",
      "arxiv:2307.10169#introduction:part-1",
      "arxiv:2310.05492#introduction:part-1"
    ],
    "relevance_scores": {
      "arxiv:2310.05492#abstract": 1.0,
      "arxiv:2211.05100#model:part-1": 1.0,
      "arxiv:2303.18223#result:part-15": 0.5,
      "arxiv:2307.10169#introduction:part-1": 0.5,
      "arxiv:2310.05492#introduction:part-1": 1.0
    },
    "notes": "Query asks about code generation capabilities. The 2310.05492 paper appears to focus on code generation. The 2211.05100 paper (BLOOM) discusses code capabilities. Papers with 1.0 directly evaluate or demonstrate code generation, while 0.5 papers mention code tasks in broader LLM evaluations."
  },
  "query_28": {
    "relevant_docs": [
      "arxiv:2307.10169#methods:part-3",
      "arxiv:2307.10169#introduction:part-1",
      "arxiv:2305.03047#introduction:part-1",
      "arxiv:2007.14966#abstract",
      "arxiv:2007.14966#model:part-1",
      "arxiv:2305.03047#abstract"
    ],
    "relevance_scores": {
      "arxiv:2307.10169#methods:part-3": 1.0,
      "arxiv:2307.10169#introduction:part-1": 1.0,
      "arxiv:2305.03047#introduction:part-1": 1.0,
      "arxiv:2007.14966#abstract": 1.0,
      "arxiv:2007.14966#model:part-1": 1.0,
      "arxiv:2305.03047#abstract": 0.5
    },
    "notes": "Query asks about retrieval-augmented language models. The 2307.10169 paper discusses RAG systems. The 2007.14966 paper is REALM (Retrieval-Augmented Language Model Pre-Training). The 2305.03047 paper discusses retrieval-augmented generation. Papers with 1.0 directly propose or analyze retrieval-augmented methods."
  },
  "query_29": {
    "relevant_docs": [
      "arxiv:2303.18223#result:part-14",
      "arxiv:2305.14314#evaluation:part-1",
      "arxiv:palm2techreport#evaluation:part-7",
      "arxiv:2303.18223#result:part-20",
      "arxiv:20-074#abstract:part-10"
    ],
    "relevance_scores": {
      "arxiv:2303.18223#result:part-14": 1.0,
      "arxiv:2305.14314#evaluation:part-1": 0.5,
      "arxiv:palm2techreport#evaluation:part-7": 0.5,
      "arxiv:2303.18223#result:part-20": 1.0,
      "arxiv:20-074#abstract:part-10": 0.5
    },
    "notes": "Query asks about performance on commonsense reasoning tasks. The 2303.18223 results sections likely evaluate commonsense benchmarks. The 2305.14314 and PaLM 2 papers include commonsense evaluations. Papers with 1.0 directly report commonsense reasoning performance with specific benchmarks."
  },
  "query_30": {
    "relevant_docs": [
      "arxiv:20-074#abstract:part-10",
      "arxiv:2020.aacl-main.88#abstract",
      "arxiv:2301.00774#introduction:part-1",
      "arxiv:20-074#introduction:part-1",
      "arxiv:2020.aacl-main.88#model:part-1"
    ],
    "relevance_scores": {
      "arxiv:20-074#abstract:part-10": 1.0,
      "arxiv:2020.aacl-main.88#abstract": 1.0,
      "arxiv:2301.00774#introduction:part-1": 0.5,
      "arxiv:20-074#introduction:part-1": 1.0,
      "arxiv:2020.aacl-main.88#model:part-1": 1.0
    },
    "notes": "Query asks about multi-task learning approaches. The 20-074 paper (T5) demonstrates multi-task training. The 2020.aacl paper discusses efficient multi-task language models. Papers with 1.0 directly propose or analyze multi-task learning methods for language models."
  }
}