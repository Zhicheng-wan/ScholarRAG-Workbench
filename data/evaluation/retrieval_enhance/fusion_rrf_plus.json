{
  "system_metrics": {
    "baseline": {
      "recall@5": 0.7321428571428571,
      "hit_rate@10": 1.0,
      "recall@3": 0.5345238095238095,
      "precision@10": 0.44952380952380955,
      "hit_rate@5": 1.0,
      "ndcg@10": 0.7321099877019595,
      "retrieval_latency": 0.005976390838623047,
      "citation_accuracy": 0.44952380952380955,
      "ndcg@3": 0.6350499802054138,
      "precision@1": 0.7,
      "precision@5": 0.54,
      "precision@3": 0.6333333333333333,
      "recall@10": 0.7607142857142857,
      "hit_rate@1": 0.7,
      "grounding_accuracy": 1.0,
      "mrr": 0.825,
      "recall@1": 0.20595238095238094,
      "ndcg@5": 0.7237737640164681,
      "hit_rate@3": 0.9,
      "ndcg@1": 0.7,
      "average_response_time": 0.005976390838623047,
      "queries_per_second": 167.32506741985415
    },
    "fusion_rrf_plus": {
      "recall@5": 0.5011904761904762,
      "hit_rate@10": 1.0,
      "recall@3": 0.3559523809523809,
      "precision@10": 0.27055555555555555,
      "hit_rate@5": 0.8,
      "ndcg@10": 0.630718506855011,
      "retrieval_latency": 1.032563042640686,
      "citation_accuracy": 0.2596581196581197,
      "ndcg@3": 0.4145729849305798,
      "precision@1": 0.6,
      "precision@5": 0.32,
      "precision@3": 0.36666666666666664,
      "recall@10": 0.7773809523809524,
      "hit_rate@1": 0.6,
      "grounding_accuracy": 1.0,
      "mrr": 0.6934523809523809,
      "recall@1": 0.1976190476190476,
      "ndcg@5": 0.4985833083622004,
      "hit_rate@3": 0.8,
      "ndcg@1": 0.55,
      "average_response_time": 1.032563042640686,
      "queries_per_second": 0.9684638697145223
    }
  },
  "best_systems": {
    "recall@5": {
      "system": "baseline",
      "score": 0.7321428571428571
    },
    "hit_rate@10": {
      "system": "baseline",
      "score": 1.0
    },
    "recall@3": {
      "system": "baseline",
      "score": 0.5345238095238095
    },
    "precision@10": {
      "system": "baseline",
      "score": 0.44952380952380955
    },
    "hit_rate@5": {
      "system": "baseline",
      "score": 1.0
    },
    "ndcg@10": {
      "system": "baseline",
      "score": 0.7321099877019595
    },
    "retrieval_latency": {
      "system": "fusion_rrf_plus",
      "score": 1.032563042640686
    },
    "citation_accuracy": {
      "system": "baseline",
      "score": 0.44952380952380955
    },
    "ndcg@3": {
      "system": "baseline",
      "score": 0.6350499802054138
    },
    "precision@1": {
      "system": "baseline",
      "score": 0.7
    },
    "precision@5": {
      "system": "baseline",
      "score": 0.54
    },
    "precision@3": {
      "system": "baseline",
      "score": 0.6333333333333333
    },
    "recall@10": {
      "system": "fusion_rrf_plus",
      "score": 0.7773809523809524
    },
    "hit_rate@1": {
      "system": "baseline",
      "score": 0.7
    },
    "grounding_accuracy": {
      "system": "baseline",
      "score": 1.0
    },
    "mrr": {
      "system": "baseline",
      "score": 0.825
    },
    "recall@1": {
      "system": "baseline",
      "score": 0.20595238095238094
    },
    "ndcg@5": {
      "system": "baseline",
      "score": 0.7237737640164681
    },
    "hit_rate@3": {
      "system": "baseline",
      "score": 0.9
    },
    "ndcg@1": {
      "system": "baseline",
      "score": 0.7
    },
    "average_response_time": {
      "system": "fusion_rrf_plus",
      "score": 1.032563042640686
    },
    "queries_per_second": {
      "system": "baseline",
      "score": 167.32506741985415
    }
  }
}