{
  "system_metrics": {
    "baseline": {
      "retrieval_latency": 0.00643159548441569,
      "hit_rate@10": 0.6666666666666666,
      "recall@1": 0.1514285714285714,
      "ndcg@3": 0.3985567699585687,
      "ndcg@5": 0.4456752767304231,
      "ndcg@10": 0.4560936662993986,
      "recall@3": 0.33706349206349207,
      "precision@3": 0.38888888888888895,
      "grounding_accuracy": 0.8135449735449735,
      "hit_rate@3": 0.6,
      "mrr": 0.5611111111111112,
      "recall@5": 0.4412698412698413,
      "citation_accuracy": 0.2706878306878307,
      "precision@5": 0.32833333333333325,
      "hit_rate@1": 0.5,
      "hit_rate@5": 0.6666666666666666,
      "ndcg@1": 0.4666666666666667,
      "precision@1": 0.5,
      "recall@10": 0.4657936507936508,
      "precision@10": 0.2706878306878307,
      "average_response_time": 0.00643159548441569,
      "queries_per_second": 155.48241527675148
    },
    "reranking": {
      "retrieval_latency": 0.441096568107605,
      "hit_rate@10": 0.6666666666666666,
      "recall@1": 0.13555555555555557,
      "ndcg@3": 0.33896324914866977,
      "ndcg@5": 0.3900370891641513,
      "ndcg@10": 0.4270682253273515,
      "recall@3": 0.29896825396825405,
      "precision@3": 0.32222222222222224,
      "grounding_accuracy": 0.8435042735042734,
      "hit_rate@3": 0.6333333333333333,
      "mrr": 0.5177777777777778,
      "recall@5": 0.39761904761904765,
      "citation_accuracy": 0.16843822843822842,
      "precision@5": 0.26666666666666666,
      "hit_rate@1": 0.43333333333333335,
      "hit_rate@5": 0.6666666666666666,
      "ndcg@1": 0.4,
      "precision@1": 0.43333333333333335,
      "recall@10": 0.4849206349206349,
      "precision@10": 0.17777777777777776,
      "average_response_time": 0.441096568107605,
      "queries_per_second": 2.267077262219939
    }
  },
  "best_systems": {
    "retrieval_latency": {
      "system": "reranking",
      "score": 0.441096568107605
    },
    "hit_rate@10": {
      "system": "baseline",
      "score": 0.6666666666666666
    },
    "recall@1": {
      "system": "baseline",
      "score": 0.1514285714285714
    },
    "ndcg@3": {
      "system": "baseline",
      "score": 0.3985567699585687
    },
    "ndcg@5": {
      "system": "baseline",
      "score": 0.4456752767304231
    },
    "ndcg@10": {
      "system": "baseline",
      "score": 0.4560936662993986
    },
    "recall@3": {
      "system": "baseline",
      "score": 0.33706349206349207
    },
    "precision@3": {
      "system": "baseline",
      "score": 0.38888888888888895
    },
    "grounding_accuracy": {
      "system": "reranking",
      "score": 0.8435042735042734
    },
    "hit_rate@3": {
      "system": "reranking",
      "score": 0.6333333333333333
    },
    "mrr": {
      "system": "baseline",
      "score": 0.5611111111111112
    },
    "recall@5": {
      "system": "baseline",
      "score": 0.4412698412698413
    },
    "citation_accuracy": {
      "system": "baseline",
      "score": 0.2706878306878307
    },
    "precision@5": {
      "system": "baseline",
      "score": 0.32833333333333325
    },
    "hit_rate@1": {
      "system": "baseline",
      "score": 0.5
    },
    "hit_rate@5": {
      "system": "baseline",
      "score": 0.6666666666666666
    },
    "ndcg@1": {
      "system": "baseline",
      "score": 0.4666666666666667
    },
    "precision@1": {
      "system": "baseline",
      "score": 0.5
    },
    "recall@10": {
      "system": "reranking",
      "score": 0.4849206349206349
    },
    "precision@10": {
      "system": "baseline",
      "score": 0.2706878306878307
    },
    "average_response_time": {
      "system": "reranking",
      "score": 0.441096568107605
    },
    "queries_per_second": {
      "system": "baseline",
      "score": 155.48241527675148
    }
  }
}